{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b75829b-28be-409f-bab2-aaa0edb5559e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'phonepe_pulse' created successfully (or already exists).\n"
     ]
    }
   ],
   "source": [
    "# --- Code to Create the Database ---\n",
    "\n",
    "import mysql.connector\n",
    "\n",
    "try:\n",
    "    # Connects to MySQL without specifying a database\n",
    "    db_connection = mysql.connector.connect(\n",
    "      host=\"127.0.0.1\",\n",
    "      user=\"root\",\n",
    "      password=\"Akshay@200\"\n",
    "    )\n",
    "    cursor = db_connection.cursor()\n",
    "\n",
    "    # This SQL command creates the database if it's missing\n",
    "    cursor.execute(\"CREATE DATABASE IF NOT EXISTS phonepe_pulse\")\n",
    "    \n",
    "    print(\"Database 'phonepe_pulse' created successfully (or already exists).\")\n",
    "    \n",
    "    cursor.close()\n",
    "    db_connection.close()\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error connecting to MySQL or creating database: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f05035f0-d86a-4831-8f4e-3723ddc9a54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspection Results for: aggregated_transaction ---\n",
      "\n",
      "Total Records Found: 1008\n",
      "\n",
      "Columns Found:\n",
      "['from', 'to', 'transactiondata', 'state', 'year', 'quarter', 'date']\n",
      "\n",
      "First 5 Rows of Data:\n",
      "            from             to  \\\n",
      "0  1514745000000  1522175400000   \n",
      "1  1522521000000  1530124200000   \n",
      "2  1530383400000  1538073000000   \n",
      "3  1538332200000  1545935400000   \n",
      "4  1546281000000  1553711400000   \n",
      "\n",
      "                                     transactiondata  \\\n",
      "0  [{'name': 'Recharge & bill payments', 'payment...   \n",
      "1  [{'name': 'Recharge & bill payments', 'payment...   \n",
      "2  [{'name': 'Recharge & bill payments', 'payment...   \n",
      "3  [{'name': 'Recharge & bill payments', 'payment...   \n",
      "4  [{'name': 'Recharge & bill payments', 'payment...   \n",
      "\n",
      "                       state  year  quarter       date  \n",
      "0  andaman-&-nicobar-islands  2018        1 2018-01-01  \n",
      "1  andaman-&-nicobar-islands  2018        2 2018-04-01  \n",
      "2  andaman-&-nicobar-islands  2018        3 2018-07-01  \n",
      "3  andaman-&-nicobar-islands  2018        4 2018-10-01  \n",
      "4  andaman-&-nicobar-islands  2019        1 2019-01-01  \n",
      "\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Inspection Code for Aggregated Transaction ---\n",
    "\n",
    "# Make sure you have run the cell that defines the 'load_regional' function first.\n",
    "\n",
    "# 1. Load the data into a DataFrame\n",
    "df_agg_txn = load_regional(\"aggregated\", \"transaction\", \"state\")\n",
    "\n",
    "# 2. Check if the DataFrame was loaded successfully\n",
    "if not df_agg_txn.empty:\n",
    "    print(\"--- Inspection Results for: aggregated_transaction ---\")\n",
    "    print(f\"\\nTotal Records Found: {len(df_agg_txn)}\")\n",
    "    print(\"\\nColumns Found:\")\n",
    "    print(list(df_agg_txn.columns))\n",
    "    print(\"\\nFirst 5 Rows of Data:\")\n",
    "    print(df_agg_txn.head())\n",
    "    print(\"\\n----------------------------------------------------\")\n",
    "else:\n",
    "    print(\"Could not load data for 'aggregated_transaction'. Please check the 'load_regional' function and file paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bec978b8-1ec1-4b2e-9a4e-dd3d144d9797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'aggregated_transaction' created successfully (or already exists).\n"
     ]
    }
   ],
   "source": [
    "# --- Create Table Code for Aggregated Transaction ---\n",
    "\n",
    "import mysql.connector\n",
    "\n",
    "try:\n",
    "    db_connection = mysql.connector.connect(\n",
    "      host=\"127.0.0.1\",\n",
    "      user=\"root\",\n",
    "      password=\"Akshay@200\",\n",
    "      database=\"phonepe_pulse\"\n",
    "    )\n",
    "    cursor = db_connection.cursor()\n",
    "\n",
    "    # This SQL command is built based on our inspection\n",
    "    create_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS aggregated_transaction (\n",
    "        state VARCHAR(100),\n",
    "        year INT,\n",
    "        quarter INT,\n",
    "        transaction_name VARCHAR(100),\n",
    "        transaction_count BIGINT,\n",
    "        transaction_amount DECIMAL(30, 2),\n",
    "        date DATE\n",
    "    );\n",
    "    \"\"\"\n",
    "    cursor.execute(create_table_query)\n",
    "    print(\"Table 'aggregated_transaction' created successfully (or already exists).\")\n",
    "    \n",
    "    db_connection.commit()\n",
    "    cursor.close()\n",
    "    db_connection.close()\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error creating table: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ac89979-08f0-4652-8e35-733c0dc3f93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5034 records have been successfully inserted into 'aggregated_transaction'.\n"
     ]
    }
   ],
   "source": [
    "# --- Process and Insert Code for Aggregated Transaction ---\n",
    "\n",
    "# We already have 'df_agg_txn' from the inspection step.\n",
    "# This code unpacks the 'transactiondata' column.\n",
    "processed_rows = []\n",
    "for index, row in df_agg_txn.iterrows():\n",
    "    for trans_data in row['transactiondata']:\n",
    "        payment_instrument = trans_data.get('paymentInstruments', [{}])[0]\n",
    "        processed_rows.append({\n",
    "            'state': row['state'],\n",
    "            'year': row['year'],\n",
    "            'quarter': row['quarter'],\n",
    "            'transaction_name': trans_data.get('name'),\n",
    "            'transaction_count': payment_instrument.get('count'),\n",
    "            'transaction_amount': payment_instrument.get('amount'),\n",
    "            'date': row['date']\n",
    "        })\n",
    "\n",
    "final_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "# Now, we insert this final_df into the table\n",
    "try:\n",
    "    db_connection = mysql.connector.connect(host=\"127.0.0.1\", user=\"root\", password=\"Akshay@200\", database=\"phonepe_pulse\")\n",
    "    cursor = db_connection.cursor()\n",
    "    \n",
    "    insert_query = \"INSERT INTO aggregated_transaction (state, year, quarter, transaction_name, transaction_count, transaction_amount, date) VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "    \n",
    "    # Convert DataFrame to list of tuples for insertion\n",
    "    data_to_insert = [tuple(row) for row in final_df.to_numpy()]\n",
    "    \n",
    "    cursor.executemany(insert_query, data_to_insert)\n",
    "    db_connection.commit()\n",
    "    \n",
    "    print(f\"{cursor.rowcount} records have been successfully inserted into 'aggregated_transaction'.\")\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Database error during insertion: {err}\")\n",
    "finally:\n",
    "    if 'db_connection' in locals() and db_connection.is_connected():\n",
    "        cursor.close()\n",
    "        db_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dccfcae-fc06-4994-97be-65f817f37023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspection Results for: aggregated_user ---\n",
      "\n",
      "Total Records Found: 1008\n",
      "\n",
      "Columns Found:\n",
      "['aggregated', 'usersbydevice', 'state', 'year', 'quarter', 'date']\n",
      "\n",
      "First 5 Rows of Data:\n",
      "                                  aggregated  \\\n",
      "0   {'registeredUsers': 6740, 'appOpens': 0}   \n",
      "1   {'registeredUsers': 9405, 'appOpens': 0}   \n",
      "2  {'registeredUsers': 12149, 'appOpens': 0}   \n",
      "3  {'registeredUsers': 15222, 'appOpens': 0}   \n",
      "4  {'registeredUsers': 18596, 'appOpens': 0}   \n",
      "\n",
      "                                       usersbydevice  \\\n",
      "0  [{'brand': 'Xiaomi', 'count': 1665, 'percentag...   \n",
      "1  [{'brand': 'Xiaomi', 'count': 2303, 'percentag...   \n",
      "2  [{'brand': 'Xiaomi', 'count': 2950, 'percentag...   \n",
      "3  [{'brand': 'Xiaomi', 'count': 3719, 'percentag...   \n",
      "4  [{'brand': 'Xiaomi', 'count': 4576, 'percentag...   \n",
      "\n",
      "                       state  year  quarter       date  \n",
      "0  andaman-&-nicobar-islands  2018        1 2018-01-01  \n",
      "1  andaman-&-nicobar-islands  2018        2 2018-04-01  \n",
      "2  andaman-&-nicobar-islands  2018        3 2018-07-01  \n",
      "3  andaman-&-nicobar-islands  2018        4 2018-10-01  \n",
      "4  andaman-&-nicobar-islands  2019        1 2019-01-01  \n",
      "\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Inspection Code for Aggregated User ---\n",
    "\n",
    "# Make sure the 'load_regional' function is defined in your notebook.\n",
    "\n",
    "# 1. Load the data into a DataFrame\n",
    "df_agg_user = load_regional(\"aggregated\", \"user\", \"state\")\n",
    "\n",
    "# 2. Check if the DataFrame was loaded successfully\n",
    "if not df_agg_user.empty:\n",
    "    print(\"--- Inspection Results for: aggregated_user ---\")\n",
    "    print(f\"\\nTotal Records Found: {len(df_agg_user)}\")\n",
    "    print(\"\\nColumns Found:\")\n",
    "    print(list(df_agg_user.columns))\n",
    "    print(\"\\nFirst 5 Rows of Data:\")\n",
    "    print(df_agg_user.head())\n",
    "    print(\"\\n-------------------------------------------------\")\n",
    "else:\n",
    "    print(\"Could not load data for 'aggregated_user'. Please check the 'load_regional' function and file paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cdfce3a-75cb-447c-98a6-1b733fe33bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'aggregated_user' created successfully (or already exists).\n"
     ]
    }
   ],
   "source": [
    "# --- Create Table Code for Aggregated User ---\n",
    "\n",
    "import mysql.connector\n",
    "\n",
    "try:\n",
    "    db_connection = mysql.connector.connect(\n",
    "      host=\"127.0.0.1\",\n",
    "      user=\"root\",\n",
    "      password=\"Akshay@200\",\n",
    "      database=\"phonepe_pulse\"\n",
    "    )\n",
    "    cursor = db_connection.cursor()\n",
    "\n",
    "    # This SQL command is built based on our inspection of the 'usersbydevice' column\n",
    "    create_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS aggregated_user (\n",
    "        state VARCHAR(100),\n",
    "        year INT,\n",
    "        quarter INT,\n",
    "        brand VARCHAR(100),\n",
    "        brand_count BIGINT,\n",
    "        brand_percentage DECIMAL(10, 5),\n",
    "        date DATE\n",
    "    );\n",
    "    \"\"\"\n",
    "    cursor.execute(create_table_query)\n",
    "    print(\"Table 'aggregated_user' created successfully (or already exists).\")\n",
    "    \n",
    "    db_connection.commit()\n",
    "    cursor.close()\n",
    "    db_connection.close()\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error creating table: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2aede6e6-7148-4863-b088-8b31d4d31f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6732 records have been successfully inserted into 'aggregated_user'.\n"
     ]
    }
   ],
   "source": [
    "# --- Process and Insert Code for Aggregated User ---\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "# We use 'df_agg_user' from the inspection step.\n",
    "# This code unpacks the 'usersbydevice' list.\n",
    "processed_rows = []\n",
    "for index, row in df_agg_user.iterrows():\n",
    "    # Safely handle cases where 'usersbydevice' might be missing or None\n",
    "    if row['usersbydevice']:\n",
    "        for device_data in row['usersbydevice']:\n",
    "            processed_rows.append({\n",
    "                'state': row.get('state'),\n",
    "                'year': row.get('year'),\n",
    "                'quarter': row.get('quarter'),\n",
    "                'brand': device_data.get('brand'),\n",
    "                'brand_count': device_data.get('count'),\n",
    "                'brand_percentage': device_data.get('percentage'),\n",
    "                'date': row.get('date')\n",
    "            })\n",
    "\n",
    "final_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "# Now, we insert the processed DataFrame into our new table\n",
    "try:\n",
    "    db_connection = mysql.connector.connect(host=\"127.0.0.1\", user=\"root\", password=\"Akshay@200\", database=\"phonepe_pulse\")\n",
    "    cursor = db_connection.cursor()\n",
    "    \n",
    "    insert_query = \"INSERT INTO aggregated_user (state, year, quarter, brand, brand_count, brand_percentage, date) VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "    \n",
    "    data_to_insert = [tuple(row) for row in final_df.to_numpy()]\n",
    "    \n",
    "    if data_to_insert:\n",
    "        cursor.executemany(insert_query, data_to_insert)\n",
    "        db_connection.commit()\n",
    "        print(f\"{cursor.rowcount} records have been successfully inserted into 'aggregated_user'.\")\n",
    "    else:\n",
    "        print(\"No processed data was available to insert.\")\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Database error during insertion: {err}\")\n",
    "finally:\n",
    "    if 'db_connection' in locals() and db_connection.is_connected():\n",
    "        cursor.close()\n",
    "        db_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ea15930-1b34-451e-958d-316bbd443b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspection Results for: aggregated_insurance ---\n",
      "\n",
      "Total Records Found: 684\n",
      "\n",
      "Columns Found:\n",
      "['from', 'to', 'transactiondata', 'state', 'year', 'quarter', 'date']\n",
      "\n",
      "First 5 Rows of Data:\n",
      "            from             to  \\\n",
      "0  1585679400000  1593282600000   \n",
      "1  1593541800000  1601231400000   \n",
      "2  1601490600000  1609093800000   \n",
      "3  1609439400000  1616869800000   \n",
      "4  1617215400000  1624818600000   \n",
      "\n",
      "                                     transactiondata  \\\n",
      "0  [{'name': 'Insurance', 'paymentInstruments': [...   \n",
      "1  [{'name': 'Insurance', 'paymentInstruments': [...   \n",
      "2  [{'name': 'Insurance', 'paymentInstruments': [...   \n",
      "3  [{'name': 'Insurance', 'paymentInstruments': [...   \n",
      "4  [{'name': 'Insurance', 'paymentInstruments': [...   \n",
      "\n",
      "                       state  year  quarter       date  \n",
      "0  andaman-&-nicobar-islands  2020        2 2020-04-01  \n",
      "1  andaman-&-nicobar-islands  2020        3 2020-07-01  \n",
      "2  andaman-&-nicobar-islands  2020        4 2020-10-01  \n",
      "3  andaman-&-nicobar-islands  2021        1 2021-01-01  \n",
      "4  andaman-&-nicobar-islands  2021        2 2021-04-01  \n",
      "\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Inspection Code for Aggregated Insurance ---\n",
    "\n",
    "# Make sure the 'load_regional' function is defined in your notebook.\n",
    "\n",
    "# 1. Load the data into a DataFrame\n",
    "df_agg_ins = load_regional(\"aggregated\", \"insurance\", \"state\")\n",
    "\n",
    "# 2. Check if the DataFrame was loaded successfully\n",
    "if not df_agg_ins.empty:\n",
    "    print(\"--- Inspection Results for: aggregated_insurance ---\")\n",
    "    print(f\"\\nTotal Records Found: {len(df_agg_ins)}\")\n",
    "    print(\"\\nColumns Found:\")\n",
    "    print(list(df_agg_ins.columns))\n",
    "    print(\"\\nFirst 5 Rows of Data:\")\n",
    "    print(df_agg_ins.head())\n",
    "    print(\"\\n----------------------------------------------------\")\n",
    "else:\n",
    "    print(\"Could not load data for 'aggregated_insurance'. Please check the 'load_regional' function and file paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f19bda3-0250-450b-be35-4458f4a0ae0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'aggregated_insurance' created successfully (or already exists).\n"
     ]
    }
   ],
   "source": [
    "# --- Create Table Code for Aggregated Insurance ---\n",
    "\n",
    "import mysql.connector\n",
    "\n",
    "try:\n",
    "    db_connection = mysql.connector.connect(\n",
    "      host=\"127.0.0.1\",\n",
    "      user=\"root\",\n",
    "      password=\"Akshay@200\",\n",
    "      database=\"phonepe_pulse\"\n",
    "    )\n",
    "    cursor = db_connection.cursor()\n",
    "\n",
    "    # This SQL command is built based on our inspection\n",
    "    create_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS aggregated_insurance (\n",
    "        state VARCHAR(100),\n",
    "        year INT,\n",
    "        quarter INT,\n",
    "        insurance_name VARCHAR(100),\n",
    "        insurance_count BIGINT,\n",
    "        insurance_amount DECIMAL(30, 2),\n",
    "        date DATE\n",
    "    );\n",
    "    \"\"\"\n",
    "    cursor.execute(create_table_query)\n",
    "    print(\"Table 'aggregated_insurance' created successfully (or already exists).\")\n",
    "    \n",
    "    db_connection.commit()\n",
    "    cursor.close()\n",
    "    db_connection.close()\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error creating table: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d82fb401-026a-44d5-8f45-f679ea82da19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "682 records have been successfully inserted into 'aggregated_insurance'.\n"
     ]
    }
   ],
   "source": [
    "# --- Process and Insert Code for Aggregated Insurance ---\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "# We use 'df_agg_ins' from the inspection step.\n",
    "processed_rows = []\n",
    "for index, row in df_agg_ins.iterrows():\n",
    "    # Safely handle cases where 'transactiondata' might be missing\n",
    "    for ins_data in row.get('transactiondata', []):\n",
    "        payment_instrument = ins_data.get('paymentInstruments', [{}])[0]\n",
    "        processed_rows.append({\n",
    "            'state': row.get('state'),\n",
    "            'year': row.get('year'),\n",
    "            'quarter': row.get('quarter'),\n",
    "            'insurance_name': ins_data.get('name'),\n",
    "            'insurance_count': payment_instrument.get('count'),\n",
    "            'insurance_amount': payment_instrument.get('amount'),\n",
    "            'date': row.get('date')\n",
    "        })\n",
    "\n",
    "final_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "# Now, we insert the processed DataFrame into our new table\n",
    "try:\n",
    "    db_connection = mysql.connector.connect(host=\"127.0.0.1\", user=\"root\", password=\"Akshay@200\", database=\"phonepe_pulse\")\n",
    "    cursor = db_connection.cursor()\n",
    "    \n",
    "    insert_query = \"INSERT INTO aggregated_insurance (state, year, quarter, insurance_name, insurance_count, insurance_amount, date) VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "    \n",
    "    data_to_insert = [tuple(row) for row in final_df.to_numpy()]\n",
    "    \n",
    "    if data_to_insert:\n",
    "        cursor.executemany(insert_query, data_to_insert)\n",
    "        db_connection.commit()\n",
    "        print(f\"{cursor.rowcount} records have been successfully inserted into 'aggregated_insurance'.\")\n",
    "    else:\n",
    "        print(\"No processed data was available to insert.\")\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Database error during insertion: {err}\")\n",
    "finally:\n",
    "    if 'db_connection' in locals() and db_connection.is_connected():\n",
    "        cursor.close()\n",
    "        db_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3da7b01-478f-403b-9cbd-10ea301a546b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspection Results for: map_transaction ---\n",
      "\n",
      "Total Records Found: 1008\n",
      "\n",
      "Columns Found:\n",
      "['hoverdatalist', 'state', 'year', 'quarter', 'date']\n",
      "\n",
      "First 5 Rows of Data:\n",
      "                                       hoverdatalist  \\\n",
      "0  [{'name': 'north and middle andaman district',...   \n",
      "1  [{'name': 'north and middle andaman district',...   \n",
      "2  [{'name': 'north and middle andaman district',...   \n",
      "3  [{'name': 'north and middle andaman district',...   \n",
      "4  [{'name': 'north and middle andaman district',...   \n",
      "\n",
      "                       state  year  quarter       date  \n",
      "0  andaman-&-nicobar-islands  2018        1 2018-01-01  \n",
      "1  andaman-&-nicobar-islands  2018        2 2018-04-01  \n",
      "2  andaman-&-nicobar-islands  2018        3 2018-07-01  \n",
      "3  andaman-&-nicobar-islands  2018        4 2018-10-01  \n",
      "4  andaman-&-nicobar-islands  2019        1 2019-01-01  \n",
      "\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Inspection Code for Map Transaction ---\n",
    "\n",
    "# Make sure the 'load_regional' function is defined in your notebook.\n",
    "\n",
    "# 1. Load the data into a DataFrame\n",
    "df_map_txn = load_regional(\"map\", \"transaction\", \"state\")\n",
    "\n",
    "# 2. Check if the DataFrame was loaded successfully\n",
    "if not df_map_txn.empty:\n",
    "    print(\"--- Inspection Results for: map_transaction ---\")\n",
    "    print(f\"\\nTotal Records Found: {len(df_map_txn)}\")\n",
    "    print(\"\\nColumns Found:\")\n",
    "    print(list(df_map_txn.columns))\n",
    "    print(\"\\nFirst 5 Rows of Data:\")\n",
    "    print(df_map_txn.head())\n",
    "    print(\"\\n-------------------------------------------------\")\n",
    "else:\n",
    "    print(\"Could not load data for 'map_transaction'. The 'load_regional' function returned an empty DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8eecff4-6918-4781-a204-491126a22cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'map_transaction' created successfully (or already exists).\n"
     ]
    }
   ],
   "source": [
    "# --- Create Table Code for Map Transaction ---\n",
    "\n",
    "import mysql.connector\n",
    "\n",
    "try:\n",
    "    db_connection = mysql.connector.connect(\n",
    "      host=\"127.0.0.1\",\n",
    "      user=\"root\",\n",
    "      password=\"Akshay@200\",\n",
    "      database=\"phonepe_pulse\"\n",
    "    )\n",
    "    cursor = db_connection.cursor()\n",
    "\n",
    "    # This SQL command is built based on our inspection of 'hoverdatalist'\n",
    "    create_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS map_transaction (\n",
    "        state VARCHAR(100),\n",
    "        year INT,\n",
    "        quarter INT,\n",
    "        district_name VARCHAR(100),\n",
    "        transaction_count BIGINT,\n",
    "        transaction_amount DECIMAL(30, 2),\n",
    "        date DATE\n",
    "    );\n",
    "    \"\"\"\n",
    "    cursor.execute(create_table_query)\n",
    "    print(\"Table 'map_transaction' created successfully (or already exists).\")\n",
    "    \n",
    "    db_connection.commit()\n",
    "    cursor.close()\n",
    "    db_connection.close()\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error creating table: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3334052-c61f-4560-aa68-270482525ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20604 records have been successfully inserted into 'map_transaction'.\n"
     ]
    }
   ],
   "source": [
    "# --- Process and Insert Code for Map Transaction ---\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "# We use 'df_map_txn' from the inspection step.\n",
    "processed_rows = []\n",
    "for index, row in df_map_txn.iterrows():\n",
    "    # THE FIX: We are now correctly looping through 'hoverdatalist'\n",
    "    for district_data in row.get('hoverdatalist', []):\n",
    "        metric = district_data.get('metric', [{}])[0]\n",
    "        processed_rows.append({\n",
    "            'state': row.get('state'),\n",
    "            'year': row.get('year'),\n",
    "            'quarter': row.get('quarter'),\n",
    "            'district_name': district_data.get('name'),\n",
    "            'transaction_count': metric.get('count'),\n",
    "            'transaction_amount': metric.get('amount'),\n",
    "            'date': row.get('date')\n",
    "        })\n",
    "\n",
    "final_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "# Now, we insert the processed DataFrame into our new table\n",
    "try:\n",
    "    db_connection = mysql.connector.connect(host=\"127.0.0.1\", user=\"root\", password=\"Akshay@200\", database=\"phonepe_pulse\")\n",
    "    cursor = db_connection.cursor()\n",
    "    \n",
    "    insert_query = \"INSERT INTO map_transaction (state, year, quarter, district_name, transaction_count, transaction_amount, date) VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "    \n",
    "    # Drop rows with missing data before inserting\n",
    "    final_df.dropna(subset=['district_name', 'transaction_count', 'transaction_amount'], inplace=True)\n",
    "    data_to_insert = [tuple(row) for row in final_df.to_numpy()]\n",
    "    \n",
    "    if data_to_insert:\n",
    "        cursor.executemany(insert_query, data_to_insert)\n",
    "        db_connection.commit()\n",
    "        print(f\"{cursor.rowcount} records have been successfully inserted into 'map_transaction'.\")\n",
    "    else:\n",
    "        print(\"No processed data was available to insert.\")\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Database error during insertion: {err}\")\n",
    "finally:\n",
    "    if 'db_connection' in locals() and db_connection.is_connected():\n",
    "        cursor.close()\n",
    "        db_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfc6f459-1eca-4a71-868e-79bed71f8410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspection Results for: map_user ---\n",
      "\n",
      "Total Records Found: 1008\n",
      "\n",
      "Columns Found:\n",
      "['hoverdata', 'state', 'year', 'quarter', 'date']\n",
      "\n",
      "First 5 Rows of Data:\n",
      "                                           hoverdata  \\\n",
      "0  {'north and middle andaman district': {'regist...   \n",
      "1  {'north and middle andaman district': {'regist...   \n",
      "2  {'north and middle andaman district': {'regist...   \n",
      "3  {'north and middle andaman district': {'regist...   \n",
      "4  {'north and middle andaman district': {'regist...   \n",
      "\n",
      "                       state  year  quarter       date  \n",
      "0  andaman-&-nicobar-islands  2018        1 2018-01-01  \n",
      "1  andaman-&-nicobar-islands  2018        2 2018-04-01  \n",
      "2  andaman-&-nicobar-islands  2018        3 2018-07-01  \n",
      "3  andaman-&-nicobar-islands  2018        4 2018-10-01  \n",
      "4  andaman-&-nicobar-islands  2019        1 2019-01-01  \n",
      "\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Inspection Code for Map User ---\n",
    "\n",
    "# Make sure the 'load_regional' function is defined in your notebook.\n",
    "\n",
    "# 1. Load the data into a DataFrame\n",
    "df_map_user = load_regional(\"map\", \"user\", \"state\")\n",
    "\n",
    "# 2. Check if the DataFrame was loaded successfully\n",
    "if not df_map_user.empty:\n",
    "    print(\"--- Inspection Results for: map_user ---\")\n",
    "    print(f\"\\nTotal Records Found: {len(df_map_user)}\")\n",
    "    print(\"\\nColumns Found:\")\n",
    "    print(list(df_map_user.columns))\n",
    "    print(\"\\nFirst 5 Rows of Data:\")\n",
    "    print(df_map_user.head())\n",
    "    print(\"\\n----------------------------------------------\")\n",
    "else:\n",
    "    print(\"Could not load data for 'map_user'. The 'load_regional' function returned an empty DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cf89426-3157-4744-80b8-ef699b221deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'map_user' created successfully (or already exists).\n"
     ]
    }
   ],
   "source": [
    "# --- Create Table Code for Map User ---\n",
    "\n",
    "import mysql.connector\n",
    "\n",
    "try:\n",
    "    db_connection = mysql.connector.connect(\n",
    "      host=\"127.0.0.1\",\n",
    "      user=\"root\",\n",
    "      password=\"Akshay@200\",\n",
    "      database=\"phonepe_pulse\"\n",
    "    )\n",
    "    cursor = db_connection.cursor()\n",
    "\n",
    "    # This SQL command is built based on our inspection of 'hoverdata'\n",
    "    create_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS map_user (\n",
    "        state VARCHAR(100),\n",
    "        year INT,\n",
    "        quarter INT,\n",
    "        district_name VARCHAR(100),\n",
    "        registered_users BIGINT,\n",
    "        app_opens BIGINT,\n",
    "        date DATE\n",
    "    );\n",
    "    \"\"\"\n",
    "    cursor.execute(create_table_query)\n",
    "    print(\"Table 'map_user' created successfully (or already exists).\")\n",
    "    \n",
    "    db_connection.commit()\n",
    "    cursor.close()\n",
    "    db_connection.close()\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error creating table: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "327cadb2-0431-4503-b339-49f095ff63cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20608 records have been successfully inserted into 'map_user'.\n"
     ]
    }
   ],
   "source": [
    "# --- Process and Insert Code for Map User ---\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "# We use 'df_map_user' from the inspection step.\n",
    "processed_rows = []\n",
    "for index, row in df_map_user.iterrows():\n",
    "    # THE FIX: We loop through the items of the 'hoverdata' dictionary\n",
    "    for district_name, metrics in row.get('hoverdata', {}).items():\n",
    "        processed_rows.append({\n",
    "            'state': row.get('state'),\n",
    "            'year': row.get('year'),\n",
    "            'quarter': row.get('quarter'),\n",
    "            'district_name': district_name,\n",
    "            'registered_users': metrics.get('registeredUsers'),\n",
    "            'app_opens': metrics.get('appOpens'),\n",
    "            'date': row.get('date')\n",
    "        })\n",
    "\n",
    "final_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "# Now, we insert the processed DataFrame into our new table\n",
    "try:\n",
    "    db_connection = mysql.connector.connect(host=\"127.0.0.1\", user=\"root\", password=\"Akshay@200\", database=\"phonepe_pulse\")\n",
    "    cursor = db_connection.cursor()\n",
    "    \n",
    "    insert_query = \"INSERT INTO map_user (state, year, quarter, district_name, registered_users, app_opens, date) VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "    \n",
    "    # Drop rows with missing data before inserting\n",
    "    final_df.dropna(subset=['district_name', 'registered_users', 'app_opens'], inplace=True)\n",
    "    data_to_insert = [tuple(row) for row in final_df.to_numpy()]\n",
    "    \n",
    "    if data_to_insert:\n",
    "        cursor.executemany(insert_query, data_to_insert)\n",
    "        db_connection.commit()\n",
    "        print(f\"{cursor.rowcount} records have been successfully inserted into 'map_user'.\")\n",
    "    else:\n",
    "        print(\"No processed data was available to insert.\")\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Database error during insertion: {err}\")\n",
    "finally:\n",
    "    if 'db_connection' in locals() and db_connection.is_connected():\n",
    "        cursor.close()\n",
    "        db_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb80888a-5dc5-4894-9ac0-cc012f05ecf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspection Results for: map_insurance ---\n",
      "\n",
      "Total Records Found: 684\n",
      "\n",
      "Columns Found:\n",
      "['meta', 'data', 'state', 'year', 'quarter', 'date']\n",
      "\n",
      "First 5 Rows of Data:\n",
      "                                                meta  \\\n",
      "0  {'dataLevel': 'STATE', 'gridLevel': 11, 'perce...   \n",
      "1  {'dataLevel': 'STATE', 'gridLevel': 11, 'perce...   \n",
      "2  {'dataLevel': 'STATE', 'gridLevel': 11, 'perce...   \n",
      "3  {'dataLevel': 'STATE', 'gridLevel': 11, 'perce...   \n",
      "4  {'dataLevel': 'STATE', 'gridLevel': 11, 'perce...   \n",
      "\n",
      "                                                data  \\\n",
      "0  {'columns': ['lat', 'lng', 'metric', 'label'],...   \n",
      "1  {'columns': ['lat', 'lng', 'metric', 'label'],...   \n",
      "2  {'columns': ['lat', 'lng', 'metric', 'label'],...   \n",
      "3  {'columns': ['lat', 'lng', 'metric', 'label'],...   \n",
      "4  {'columns': ['lat', 'lng', 'metric', 'label'],...   \n",
      "\n",
      "                       state  year  quarter       date  \n",
      "0  andaman-&-nicobar-islands  2020        2 2020-04-01  \n",
      "1  andaman-&-nicobar-islands  2020        3 2020-07-01  \n",
      "2  andaman-&-nicobar-islands  2020        4 2020-10-01  \n",
      "3  andaman-&-nicobar-islands  2021        1 2021-01-01  \n",
      "4  andaman-&-nicobar-islands  2021        2 2021-04-01  \n",
      "\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Inspection Code for Map Insurance ---\n",
    "\n",
    "# Make sure the final 'load_regional' function is defined in your notebook.\n",
    "\n",
    "# 1. Load the data into a DataFrame\n",
    "df_map_ins = load_regional(\"map\", \"insurance\", \"state\")\n",
    "\n",
    "# 2. Check if the DataFrame was loaded successfully\n",
    "if not df_map_ins.empty:\n",
    "    print(\"--- Inspection Results for: map_insurance ---\")\n",
    "    print(f\"\\nTotal Records Found: {len(df_map_ins)}\")\n",
    "    print(\"\\nColumns Found:\")\n",
    "    print(list(df_map_ins.columns))\n",
    "    print(\"\\nFirst 5 Rows of Data:\")\n",
    "    print(df_map_ins.head())\n",
    "    print(\"\\n-------------------------------------------------\")\n",
    "else:\n",
    "    print(\"Could not load data for 'map_insurance'. The 'load_regional' function returned an empty DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76dab42a-bfd9-4a34-b270-f86d8a3ee015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'map_insurance' is now ready and empty.\n"
     ]
    }
   ],
   "source": [
    "# --- Final Create Table command for map_insurance ---\n",
    "import mysql.connector\n",
    "\n",
    "# These variables should already be defined from our previous steps\n",
    "# db_host = \"127.0.0.1\"\n",
    "# db_user = \"root\"\n",
    "# db_pass = \"Akshay@200\"\n",
    "# db_name = \"phonepe_pulse\"\n",
    "\n",
    "try:\n",
    "    db_connection = mysql.connector.connect(\n",
    "        host=db_host,\n",
    "        user=db_user,\n",
    "        password=db_pass,\n",
    "        database=db_name\n",
    "    )\n",
    "    cursor = db_connection.cursor()\n",
    "\n",
    "    create_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS map_insurance (\n",
    "        state VARCHAR(100),\n",
    "        year INT,\n",
    "        quarter INT,\n",
    "        district_name VARCHAR(100),\n",
    "        insurance_count BIGINT,\n",
    "        insurance_amount DECIMAL(30, 2),\n",
    "        date DATE\n",
    "    );\n",
    "    \"\"\"\n",
    "    cursor.execute(create_table_query)\n",
    "    \n",
    "    # This line clears any old data from the table\n",
    "    cursor.execute(\"TRUNCATE TABLE map_insurance;\")\n",
    "    \n",
    "    print(\"Table 'map_insurance' is now ready and empty.\")\n",
    "    \n",
    "    db_connection.commit()\n",
    "    cursor.close()\n",
    "    db_connection.close()\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error preparing table: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c747a310-5f82-4811-803f-6acba941aed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: 1043137 records have been inserted into 'map_insurance'.\n"
     ]
    }
   ],
   "source": [
    "# --- Final Process and Insert Code for map_insurance ---\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "# This line assumes 'df_map_ins' still exists in your notebook's memory from the inspection step.\n",
    "processed_rows = []\n",
    "for index, row in df_map_ins.iterrows():\n",
    "    # Correctly navigate the nested structure: row -> 'data' (dict) -> 'data' (list of lists)\n",
    "    for district_list in row.get('data', {}).get('data', []):\n",
    "        # Safety check: ensure the inner list has enough items\n",
    "        if len(district_list) > 3:\n",
    "            # The metric is a single value (count), not a dictionary\n",
    "            insurance_count = district_list[2] \n",
    "            # The district name is the 'label'\n",
    "            district_name = district_list[3]\n",
    "            \n",
    "            processed_rows.append({\n",
    "                'state': row.get('state'),\n",
    "                'year': row.get('year'),\n",
    "                'quarter': row.get('quarter'),\n",
    "                'district_name': district_name,\n",
    "                'insurance_count': insurance_count,\n",
    "                # This data file only provides count, so we set amount to 0\n",
    "                'insurance_amount': 0, \n",
    "                'date': row.get('date')\n",
    "            })\n",
    "\n",
    "final_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "# Now, we insert the processed DataFrame into our table\n",
    "try:\n",
    "    # Using the verified variables\n",
    "    db_connection = mysql.connector.connect(\n",
    "        host=db_host,\n",
    "        user=db_user,\n",
    "        password=db_pass,\n",
    "        database=db_name\n",
    "    )\n",
    "    cursor = db_connection.cursor()\n",
    "    \n",
    "    insert_query = \"INSERT INTO map_insurance (state, year, quarter, district_name, insurance_count, insurance_amount, date) VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "    \n",
    "    # Drop rows where essential data might be missing\n",
    "    final_df.dropna(subset=['district_name', 'insurance_count'], inplace=True)\n",
    "    data_to_insert = [tuple(row) for row in final_df.to_numpy()]\n",
    "    \n",
    "    # --- Using batch insertion to prevent timeouts ---\n",
    "    batch_size = 1000\n",
    "    total_inserted = 0\n",
    "    for i in range(0, len(data_to_insert), batch_size):\n",
    "        batch = data_to_insert[i:i+batch_size]\n",
    "        if batch:\n",
    "            cursor.executemany(insert_query, batch)\n",
    "            db_connection.commit()\n",
    "            total_inserted += cursor.rowcount\n",
    "            \n",
    "    print(f\"SUCCESS: {total_inserted} records have been inserted into 'map_insurance'.\")\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"DATABASE ERROR during insertion: {err}\")\n",
    "finally:\n",
    "    if 'db_connection' in locals() and db_connection.is_connected():\n",
    "        cursor.close()\n",
    "        db_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d01af717-c54e-49a1-8ae3-c7885a979f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspection Results for: top_transaction ---\n",
      "\n",
      "Total Records Found: 1008\n",
      "\n",
      "Columns Found:\n",
      "['states', 'districts', 'pincodes', 'state', 'year', 'quarter', 'date']\n",
      "\n",
      "First 5 Rows of Data:\n",
      "  states                                          districts  \\\n",
      "0   None  [{'entityName': 'south andaman', 'metric': {'t...   \n",
      "1   None  [{'entityName': 'south andaman', 'metric': {'t...   \n",
      "2   None  [{'entityName': 'south andaman', 'metric': {'t...   \n",
      "3   None  [{'entityName': 'south andaman', 'metric': {'t...   \n",
      "4   None  [{'entityName': 'south andaman', 'metric': {'t...   \n",
      "\n",
      "                                            pincodes  \\\n",
      "0  [{'entityName': '744101', 'metric': {'type': '...   \n",
      "1  [{'entityName': '744101', 'metric': {'type': '...   \n",
      "2  [{'entityName': '744101', 'metric': {'type': '...   \n",
      "3  [{'entityName': '744101', 'metric': {'type': '...   \n",
      "4  [{'entityName': '744103', 'metric': {'type': '...   \n",
      "\n",
      "                       state  year  quarter       date  \n",
      "0  andaman-&-nicobar-islands  2018        1 2018-01-01  \n",
      "1  andaman-&-nicobar-islands  2018        2 2018-04-01  \n",
      "2  andaman-&-nicobar-islands  2018        3 2018-07-01  \n",
      "3  andaman-&-nicobar-islands  2018        4 2018-10-01  \n",
      "4  andaman-&-nicobar-islands  2019        1 2019-01-01  \n",
      "\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Inspection Code for Top Transaction ---\n",
    "\n",
    "# Make sure the final 'load_regional' function is defined in your notebook.\n",
    "\n",
    "# 1. Load the data into a DataFrame\n",
    "df_top_txn = load_regional(\"top\", \"transaction\", \"state\")\n",
    "\n",
    "# 2. Check if the DataFrame was loaded successfully\n",
    "if not df_top_txn.empty:\n",
    "    print(\"--- Inspection Results for: top_transaction ---\")\n",
    "    print(f\"\\nTotal Records Found: {len(df_top_txn)}\")\n",
    "    print(\"\\nColumns Found:\")\n",
    "    print(list(df_top_txn.columns))\n",
    "    print(\"\\nFirst 5 Rows of Data:\")\n",
    "    print(df_top_txn.head())\n",
    "    print(\"\\n-------------------------------------------------\")\n",
    "else:\n",
    "    print(\"Could not load data for 'top_transaction'. The 'load_regional' function returned an empty DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3477966c-b724-4dfe-8c90-d0bcb87a96e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'top_transaction' created successfully (or already exists).\n"
     ]
    }
   ],
   "source": [
    "# --- Create Table Code for Top Transaction ---\n",
    "\n",
    "import mysql.connector\n",
    "\n",
    "try:\n",
    "    # Using the verified variables from our previous step\n",
    "    db_connection = mysql.connector.connect(\n",
    "        host=db_host,\n",
    "        user=db_user,\n",
    "        password=db_pass,\n",
    "        database=db_name\n",
    "    )\n",
    "    cursor = db_connection.cursor()\n",
    "\n",
    "    # This SQL command is built to hold both districts and pincodes\n",
    "    create_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS top_transaction (\n",
    "        state VARCHAR(100),\n",
    "        year INT,\n",
    "        quarter INT,\n",
    "        entity_name VARCHAR(100),\n",
    "        entity_type VARCHAR(20),\n",
    "        transaction_count BIGINT,\n",
    "        transaction_amount DECIMAL(30, 2),\n",
    "        date DATE\n",
    "    );\n",
    "    \"\"\"\n",
    "    cursor.execute(create_table_query)\n",
    "    print(\"Table 'top_transaction' created successfully (or already exists).\")\n",
    "\n",
    "    db_connection.commit()\n",
    "    cursor.close()\n",
    "    db_connection.close()\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error creating table: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7f737f1-541d-4e63-818b-02d02dbc88a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18293 records have been successfully inserted into 'top_transaction'.\n"
     ]
    }
   ],
   "source": [
    "# --- Process and Insert Code for Top Transaction ---\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "# We use 'df_top_txn' from the inspection step.\n",
    "processed_rows = []\n",
    "for index, row in df_top_txn.iterrows():\n",
    "    # First, process the list of top districts\n",
    "    for district in row.get('districts', []):\n",
    "        metric = district.get('metric', {})\n",
    "        processed_rows.append({\n",
    "            'state': row.get('state'),\n",
    "            'year': row.get('year'),\n",
    "            'quarter': row.get('quarter'),\n",
    "            'entity_name': district.get('entityName'),\n",
    "            'entity_type': 'district', # Mark this row as a district\n",
    "            'transaction_count': metric.get('count'),\n",
    "            'transaction_amount': metric.get('amount'),\n",
    "            'date': row.get('date')\n",
    "        })\n",
    "    # Next, process the list of top pincodes\n",
    "    for pincode in row.get('pincodes', []):\n",
    "        metric = pincode.get('metric', {})\n",
    "        processed_rows.append({\n",
    "            'state': row.get('state'),\n",
    "            'year': row.get('year'),\n",
    "            'quarter': row.get('quarter'),\n",
    "            'entity_name': pincode.get('entityName'),\n",
    "            'entity_type': 'pincode', # Mark this row as a pincode\n",
    "            'transaction_count': metric.get('count'),\n",
    "            'transaction_amount': metric.get('amount'),\n",
    "            'date': row.get('date')\n",
    "        })\n",
    "\n",
    "final_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "# Now, we insert the combined DataFrame into our new table\n",
    "try:\n",
    "    # Using the verified variables from our previous step\n",
    "    db_connection = mysql.connector.connect(\n",
    "        host=db_host,\n",
    "        user=db_user,\n",
    "        password=db_pass,\n",
    "        database=db_name\n",
    "    )\n",
    "    cursor = db_connection.cursor()\n",
    "\n",
    "    insert_query = \"INSERT INTO top_transaction (state, year, quarter, entity_name, entity_type, transaction_count, transaction_amount, date) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "    final_df.dropna(subset=['entity_name', 'transaction_count', 'transaction_amount'], inplace=True)\n",
    "    data_to_insert = [tuple(row) for row in final_df.to_numpy()]\n",
    "\n",
    "    if data_to_insert:\n",
    "        cursor.executemany(insert_query, data_to_insert)\n",
    "        db_connection.commit()\n",
    "        print(f\"{cursor.rowcount} records have been successfully inserted into 'top_transaction'.\")\n",
    "    else:\n",
    "        print(\"No processed data was available to insert.\")\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Database error during insertion: {err}\")\n",
    "finally:\n",
    "    if 'db_connection' in locals() and db_connection.is_connected():\n",
    "        cursor.close()\n",
    "        db_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "609d6844-8edc-4118-a8f7-e1b4428944b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspection Results for: top_user ---\n",
      "\n",
      "Total Records Found: 1008\n",
      "\n",
      "Columns Found:\n",
      "['states', 'districts', 'pincodes', 'state', 'year', 'quarter', 'date']\n",
      "\n",
      "First 5 Rows of Data:\n",
      "  states                                          districts  \\\n",
      "0   None  [{'name': 'south andaman', 'registeredUsers': ...   \n",
      "1   None  [{'name': 'south andaman', 'registeredUsers': ...   \n",
      "2   None  [{'name': 'south andaman', 'registeredUsers': ...   \n",
      "3   None  [{'name': 'south andaman', 'registeredUsers': ...   \n",
      "4   None  [{'name': 'south andaman', 'registeredUsers': ...   \n",
      "\n",
      "                                            pincodes  \\\n",
      "0  [{'name': '744103', 'registeredUsers': 1608}, ...   \n",
      "1  [{'name': '744103', 'registeredUsers': 2188}, ...   \n",
      "2  [{'name': '744103', 'registeredUsers': 2741}, ...   \n",
      "3  [{'name': '744103', 'registeredUsers': 3373}, ...   \n",
      "4  [{'name': '744103', 'registeredUsers': 4136}, ...   \n",
      "\n",
      "                       state  year  quarter       date  \n",
      "0  andaman-&-nicobar-islands  2018        1 2018-01-01  \n",
      "1  andaman-&-nicobar-islands  2018        2 2018-04-01  \n",
      "2  andaman-&-nicobar-islands  2018        3 2018-07-01  \n",
      "3  andaman-&-nicobar-islands  2018        4 2018-10-01  \n",
      "4  andaman-&-nicobar-islands  2019        1 2019-01-01  \n",
      "\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Inspection Code for Top User ---\n",
    "\n",
    "# Make sure the final 'load_regional' function is defined in your notebook.\n",
    "\n",
    "# 1. Load the data into a DataFrame\n",
    "df_top_user = load_regional(\"top\", \"user\", \"state\")\n",
    "\n",
    "# 2. Check if the DataFrame was loaded successfully\n",
    "if not df_top_user.empty:\n",
    "    print(\"--- Inspection Results for: top_user ---\")\n",
    "    print(f\"\\nTotal Records Found: {len(df_top_user)}\")\n",
    "    print(\"\\nColumns Found:\")\n",
    "    print(list(df_top_user.columns))\n",
    "    print(\"\\nFirst 5 Rows of Data:\")\n",
    "    print(df_top_user.head())\n",
    "    print(\"\\n----------------------------------------------\")\n",
    "else:\n",
    "    print(\"Could not load data for 'top_user'. The 'load_regional' function returned an empty DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f0e1586-b362-45ab-8e68-511ad98cfad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'top_user' created successfully (or already exists).\n"
     ]
    }
   ],
   "source": [
    "# --- Create Table Code for Top User ---\n",
    "\n",
    "import mysql.connector\n",
    "\n",
    "try:\n",
    "    # Using the verified variables from our previous step\n",
    "    db_connection = mysql.connector.connect(\n",
    "        host=db_host,\n",
    "        user=db_user,\n",
    "        password=db_pass,\n",
    "        database=db_name\n",
    "    )\n",
    "    cursor = db_connection.cursor()\n",
    "\n",
    "    # This SQL command is built to hold both districts and pincodes\n",
    "    create_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS top_user (\n",
    "        state VARCHAR(100),\n",
    "        year INT,\n",
    "        quarter INT,\n",
    "        entity_name VARCHAR(100),\n",
    "        entity_type VARCHAR(20),\n",
    "        registered_users BIGINT,\n",
    "        date DATE\n",
    "    );\n",
    "    \"\"\"\n",
    "    cursor.execute(create_table_query)\n",
    "    print(\"Table 'top_user' created successfully (or already exists).\")\n",
    "\n",
    "    db_connection.commit()\n",
    "    cursor.close()\n",
    "    db_connection.close()\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error creating table: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c68b1c3-b8a8-4507-94d7-f36bf4e37772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18296 records have been successfully inserted into 'top_user'.\n"
     ]
    }
   ],
   "source": [
    "# --- Process and Insert Code for Top User ---\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "# We use 'df_top_user' from the inspection step.\n",
    "processed_rows = []\n",
    "for index, row in df_top_user.iterrows():\n",
    "    # First, process the list of top districts\n",
    "    for district in row.get('districts', []):\n",
    "        processed_rows.append({\n",
    "            'state': row.get('state'),\n",
    "            'year': row.get('year'),\n",
    "            'quarter': row.get('quarter'),\n",
    "            'entity_name': district.get('name'),\n",
    "            'entity_type': 'district', # Mark this row as a district\n",
    "            'registered_users': district.get('registeredUsers'),\n",
    "            'date': row.get('date')\n",
    "        })\n",
    "    # Next, process the list of top pincodes\n",
    "    for pincode in row.get('pincodes', []):\n",
    "        processed_rows.append({\n",
    "            'state': row.get('state'),\n",
    "            'year': row.get('year'),\n",
    "            'quarter': row.get('quarter'),\n",
    "            'entity_name': pincode.get('name'),\n",
    "            'entity_type': 'pincode', # Mark this row as a pincode\n",
    "            'registered_users': pincode.get('registeredUsers'),\n",
    "            'date': row.get('date')\n",
    "        })\n",
    "\n",
    "final_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "# Now, we insert the combined DataFrame into our new table\n",
    "try:\n",
    "    # Using the verified variables\n",
    "    db_connection = mysql.connector.connect(\n",
    "        host=db_host,\n",
    "        user=db_user,\n",
    "        password=db_pass,\n",
    "        database=db_name\n",
    "    )\n",
    "    cursor = db_connection.cursor()\n",
    "\n",
    "    insert_query = \"INSERT INTO top_user (state, year, quarter, entity_name, entity_type, registered_users, date) VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "    final_df.dropna(subset=['entity_name', 'registered_users'], inplace=True)\n",
    "    data_to_insert = [tuple(row) for row in final_df.to_numpy()]\n",
    "\n",
    "    if data_to_insert:\n",
    "        cursor.executemany(insert_query, data_to_insert)\n",
    "        db_connection.commit()\n",
    "        print(f\"{cursor.rowcount} records have been successfully inserted into 'top_user'.\")\n",
    "    else:\n",
    "        print(\"No processed data was available to insert.\")\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Database error during insertion: {err}\")\n",
    "finally:\n",
    "    if 'db_connection' in locals() and db_connection.is_connected():\n",
    "        cursor.close()\n",
    "        db_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "697fa545-9b9d-4420-bf5e-511e9fbc3f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspection Results for: top_insurance ---\n",
      "\n",
      "Total Records Found: 684\n",
      "\n",
      "Columns Found:\n",
      "['states', 'districts', 'pincodes', 'state', 'year', 'quarter', 'date']\n",
      "\n",
      "First 5 Rows of Data:\n",
      "  states                                          districts  \\\n",
      "0   None  [{'entityName': 'nicobars', 'metric': {'type':...   \n",
      "1   None  [{'entityName': 'south andaman', 'metric': {'t...   \n",
      "2   None  [{'entityName': 'south andaman', 'metric': {'t...   \n",
      "3   None  [{'entityName': 'south andaman', 'metric': {'t...   \n",
      "4   None  [{'entityName': 'south andaman', 'metric': {'t...   \n",
      "\n",
      "                                            pincodes  \\\n",
      "0  [{'entityName': '744301', 'metric': {'type': '...   \n",
      "1  [{'entityName': '744112', 'metric': {'type': '...   \n",
      "2  [{'entityName': '744105', 'metric': {'type': '...   \n",
      "3  [{'entityName': '744105', 'metric': {'type': '...   \n",
      "4  [{'entityName': '744103', 'metric': {'type': '...   \n",
      "\n",
      "                       state  year  quarter       date  \n",
      "0  andaman-&-nicobar-islands  2020        2 2020-04-01  \n",
      "1  andaman-&-nicobar-islands  2020        3 2020-07-01  \n",
      "2  andaman-&-nicobar-islands  2020        4 2020-10-01  \n",
      "3  andaman-&-nicobar-islands  2021        1 2021-01-01  \n",
      "4  andaman-&-nicobar-islands  2021        2 2021-04-01  \n",
      "\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Inspection Code for Top Insurance ---\n",
    "\n",
    "# Make sure the final 'load_regional' function is defined in your notebook.\n",
    "\n",
    "# 1. Load the data into a DataFrame\n",
    "df_top_ins = load_regional(\"top\", \"insurance\", \"state\")\n",
    "\n",
    "# 2. Check if the DataFrame was loaded successfully\n",
    "if not df_top_ins.empty:\n",
    "    print(\"--- Inspection Results for: top_insurance ---\")\n",
    "    print(f\"\\nTotal Records Found: {len(df_top_ins)}\")\n",
    "    print(\"\\nColumns Found:\")\n",
    "    print(list(df_top_ins.columns))\n",
    "    print(\"\\nFirst 5 Rows of Data:\")\n",
    "    print(df_top_ins.head())\n",
    "    print(\"\\n-------------------------------------------------\")\n",
    "else:\n",
    "    print(\"Could not load data for 'top_insurance'. The 'load_regional' function returned an empty DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19cd7f15-0640-4d27-903c-843db331b438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'top_insurance' created successfully (or already exists).\n"
     ]
    }
   ],
   "source": [
    "# --- Create Table Code for Top Insurance ---\n",
    "\n",
    "import mysql.connector\n",
    "\n",
    "try:\n",
    "    # Using the verified variables from our previous step\n",
    "    db_connection = mysql.connector.connect(\n",
    "        host=db_host,\n",
    "        user=db_user,\n",
    "        password=db_pass,\n",
    "        database=db_name\n",
    "    )\n",
    "    cursor = db_connection.cursor()\n",
    "\n",
    "    # This SQL command is built to hold both districts and pincodes\n",
    "    create_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS top_insurance (\n",
    "        state VARCHAR(100),\n",
    "        year INT,\n",
    "        quarter INT,\n",
    "        entity_name VARCHAR(100),\n",
    "        entity_type VARCHAR(20),\n",
    "        insurance_count BIGINT,\n",
    "        insurance_amount DECIMAL(30, 2),\n",
    "        date DATE\n",
    "    );\n",
    "    \"\"\"\n",
    "    cursor.execute(create_table_query)\n",
    "    print(\"Table 'top_insurance' created successfully (or already exists).\")\n",
    "\n",
    "    db_connection.commit()\n",
    "    cursor.close()\n",
    "    db_connection.close()\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error creating table: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7d1dbe2-df44-471a-807c-2573f53951ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12273 records have been successfully inserted into 'top_insurance'.\n"
     ]
    }
   ],
   "source": [
    "# --- Process and Insert Code for Top Insurance ---\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "# We use 'df_top_ins' from the inspection step.\n",
    "processed_rows = []\n",
    "for index, row in df_top_ins.iterrows():\n",
    "    # First, process the list of top districts\n",
    "    for district in row.get('districts', []):\n",
    "        metric = district.get('metric', {})\n",
    "        processed_rows.append({\n",
    "            'state': row.get('state'),\n",
    "            'year': row.get('year'),\n",
    "            'quarter': row.get('quarter'),\n",
    "            'entity_name': district.get('entityName'),\n",
    "            'entity_type': 'district', # Mark this row as a district\n",
    "            'insurance_count': metric.get('count'),\n",
    "            'insurance_amount': metric.get('amount'),\n",
    "            'date': row.get('date')\n",
    "        })\n",
    "    # Next, process the list of top pincodes\n",
    "    for pincode in row.get('pincodes', []):\n",
    "        metric = pincode.get('metric', {})\n",
    "        processed_rows.append({\n",
    "            'state': row.get('state'),\n",
    "            'year': row.get('year'),\n",
    "            'quarter': row.get('quarter'),\n",
    "            'entity_name': pincode.get('entityName'),\n",
    "            'entity_type': 'pincode', # Mark this row as a pincode\n",
    "            'insurance_count': metric.get('count'),\n",
    "            'insurance_amount': metric.get('amount'),\n",
    "            'date': row.get('date')\n",
    "        })\n",
    "\n",
    "final_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "# Now, we insert the combined DataFrame into our new table\n",
    "try:\n",
    "    # Using the verified variables\n",
    "    db_connection = mysql.connector.connect(\n",
    "        host=db_host,\n",
    "        user=db_user,\n",
    "        password=db_pass,\n",
    "        database=db_name\n",
    "    )\n",
    "    cursor = db_connection.cursor()\n",
    "\n",
    "    insert_query = \"INSERT INTO top_insurance (state, year, quarter, entity_name, entity_type, insurance_count, insurance_amount, date) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "    final_df.dropna(subset=['entity_name', 'insurance_count', 'insurance_amount'], inplace=True)\n",
    "    data_to_insert = [tuple(row) for row in final_df.to_numpy()]\n",
    "\n",
    "    if data_to_insert:\n",
    "        cursor.executemany(insert_query, data_to_insert)\n",
    "        db_connection.commit()\n",
    "        print(f\"{cursor.rowcount} records have been successfully inserted into 'top_insurance'.\")\n",
    "    else:\n",
    "        print(\"No processed data was available to insert.\")\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Database error during insertion: {err}\")\n",
    "finally:\n",
    "    if 'db_connection' in locals() and db_connection.is_connected():\n",
    "        cursor.close()\n",
    "        db_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093fa66c-152c-45d2-a5c3-d986065d853c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108f18e5-0505-4ea0-a37e-93648fab5e17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd884ab-3d37-4531-9559-d3baa5097207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd605ea-3fdd-43e4-9c1e-6c8bcb34a78c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1771a80d-8ff9-4c18-a8d5-79f0ab255c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6857e72-65c7-4ff8-96cc-fc14be930515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb88121-32f0-4c1b-a046-cb851a989459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17419953-3979-43fb-aab3-cc2a6bee7430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecade6c-7158-4b70-8da0-c306b02cecc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a030751-fa4e-4a12-8685-18f93eec7f38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159eb230-b17b-48da-8c81-e531070892f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
